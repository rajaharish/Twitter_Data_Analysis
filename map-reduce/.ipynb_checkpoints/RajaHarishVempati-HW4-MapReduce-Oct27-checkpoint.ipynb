{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mrjobs as mr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 4\n",
    "\n",
    "Copy this notebook. Rename it as: YOURNAME-HW4-mapreduce-XX\n",
    "\n",
    "with your name replacing YOURNAME and the xx replaced with the date you submit or copy this HW.\n",
    "\n",
    ".\n",
    "\n",
    "Upload your completed jupyter notebook to elearning site as your homework submission. Do not put this notebook on your github.\n",
    "\n",
    "\n",
    "Do all the homeworks problems below:\n",
    "As noted doing the homework gets a 3 out of 5. To do more create tutorials on how to use Map reduce for different analysis that were not assigned in this HW.\n",
    "\n",
    "Use the data+shakes.nonpunc.txt file as the source of you analysis in this homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Homework 4.1\n",
    " A bigram is the combination of words.  Find the 10 most common bigrams from the text.  Order counts in the bigram combination for example \"in the\" is not the same bigram as \"the in\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 7.0.3, however version 7.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /Users/harish/Documents/anaconda/anaconda/lib/python2.7/site-packages\n"
     ]
    }
   ],
   "source": [
    "import pip    \n",
    "def install(package):\n",
    "   pip.main(['install', package])\n",
    "\n",
    "#install('mrjob')\n",
    "install('nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordCount.py\n"
     ]
    }
   ],
   "source": [
    "%%file WordCount.py\n",
    "\n",
    "import re\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "\n",
    "    lastWord=None\n",
    "   \n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        global lastWord\n",
    "        if lastWord is None:\n",
    "           lastWord = \"\"\n",
    "        line=lastWord+line\n",
    "        yield \"chars\", len(line)\n",
    "        yield \"words\", len(line.split())\n",
    "        yield \"lines\", 1\n",
    "        yield \"Bi grams\", len(re.findall(\"\\w+\",line))\n",
    "        yield \"last\", len(lastWord)\n",
    "        lastWord = line.split()[-1]\n",
    "        \n",
    "        \n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no configs found; falling back on auto-configuration\n",
      "no configs found; falling back on auto-configuration\n",
      "creating tmp directory /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834\n",
      "\n",
      "PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "\n",
      "writing to /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834/step-0-mapper-sorted\n",
      "> sort /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834/step-0-mapper_part-00000\n",
      "writing to /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834/step-0-reducer_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834/step-0-reducer_part-00000 -> /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834/output/part-00000\n",
      "Streaming final output from /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834/output\n",
      "\"Bi grams\"\t30\n",
      "\"chars\"\t171\n",
      "\"last\"\t3\n",
      "\"lines\"\t2\n",
      "\"words\"\t30\n",
      "removing tmp directory /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordCount.harish.20151020.203251.133834\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!python WordCount.py bible+shakes.nopunc.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRBiGramCount.py\n"
     ]
    }
   ],
   "source": [
    "%%file MRBiGramCount.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "lastWord=None\n",
    "\n",
    "class MRBiGramCount(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        # yield each word in the line\n",
    "        # for word in WORD_RE.findall(line):\n",
    "        if len(line.strip()) != 0 :\n",
    "            global lastWord\n",
    "            if lastWord is None:\n",
    "                lastWord = \"\"\n",
    "            updatedline=lastWord+\" \"+line\n",
    "            newword=nltk.word_tokenize(updatedline)\n",
    "            print list(nltk.bigrams(newword))\n",
    "            for word in nltk.bigrams(newword):\n",
    "                yield (word, 1)\n",
    "            #if(len(line.split()) > 0):\n",
    "            lastWord = updatedline.split()[-1]\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        SORT_VALUES = True\n",
    "        yield (word),sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    counter=0\n",
    "    MRBiGramCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.runner\"\n",
      "[('holy', 'bible'), ('bible', 'authorized'), ('authorized', 'king'), ('king', 'james'), ('james', 'version'), ('version', 'textfile'), ('textfile', '890904')]\n",
      "[('890904', 'daffar')]\n",
      "[('daffar', 'hello')]\n",
      "[('hello', 'die'), ('die', 'of')]\n",
      "[(\"('daffar', 'hello')\", 1), (\"('890904', 'daffar')\", 1), (\"('textfile', '890904')\", 1), (\"('authorized', 'king')\", 1), (\"('die', 'of')\", 1), (\"('bible', 'authorized')\", 1), (\"('holy', 'bible')\", 1), (\"('hello', 'die')\", 1), (\"('king', 'james')\", 1), (\"('james', 'version')\", 1)]\n"
     ]
    }
   ],
   "source": [
    "!python BiGramRunner.py sorted_bigram.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Homework 4.2\n",
    "Now do the same analysis but make the word order not count \"in the\" == \"the in\".  Find the 10 most common ordered bigrams from the alice text.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SortedBiGramCount.py\n"
     ]
    }
   ],
   "source": [
    "%%file SortedBiGramCount.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "lastWord=None\n",
    "counter=0\n",
    "class SortedBiGramCount(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        # yield each word in the line\n",
    "        # for word in WORD_RE.findall(line):\n",
    "        global lastWord\n",
    "        global counter\n",
    "        if lastWord is None:\n",
    "            lastWord = \"\"\n",
    "        updatedline=lastWord+\" \"+line\n",
    "        newword=nltk.word_tokenize(updatedline)\n",
    "        for word in nltk.bigrams(newword):\n",
    "            sortedbigram= sorted(word)\n",
    "            yield (sortedbigram, 1)\n",
    "        if(len(line.split()) <= 0):\n",
    "            counter=counter+1\n",
    "            #print counter\n",
    "        else:\n",
    "             lastWord = updatedline.split()[-1]\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        SORT_VALUES = True\n",
    "        yield (word),sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    counter=0\n",
    "    SortedBiGramCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.runner\"\n",
      "[(\"('of', 'the')\", 13082), (\"('lord', 'the')\", 7419), (\"('and', 'the')\", 7071), (\"('in', 'the')\", 6783), (\"('i', 'will')\", 4156), (\"('the', 'to')\", 3822), (\"('have', 'i')\", 3182), (\"('and', 'he')\", 3160), (\"('be', 'shall')\", 3018), (\"('am', 'i')\", 2912)]\n"
     ]
    }
   ],
   "source": [
    "!python sortedbigram_runner.py data/bible+shakes.nopunc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Homework 4.3\n",
    "A trigram are three word combintation.  Find the 10 most common ordered trigrams from the alice text.  Make it so that the order of the words do not count in the trigram combination for example \"in the air\" is the same trigram as \"the air in\" or \"air in the\"...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SortedTriGramCount.py\n"
     ]
    }
   ],
   "source": [
    "%%file SortedTriGramCount.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "lastWord=None\n",
    "\n",
    "class SortedTriGramCount(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        # yield each word in the line\n",
    "        # for word in WORD_RE.findall(line):\n",
    "        global lastWord\n",
    "        global counter\n",
    "        if len(line.strip()) != 0 :\n",
    "            if lastWord is None:\n",
    "                lastWord = \"\"\n",
    "            from_prev_line=\" \".join(lastWord)    \n",
    "            updatedline=from_prev_line+\" \"+line\n",
    "            newword=nltk.word_tokenize(updatedline)\n",
    "            for word in nltk.ngrams(newword,3):\n",
    "                sortedbigram= sorted(word)\n",
    "                yield (sortedbigram, 1)\n",
    "                lastWord = updatedline.split()[-2:]\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        SORT_VALUES = True\n",
    "        yield (word),sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    SortedTriGramCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.runner\"\n",
      "[(\"('lord', 'of', 'the')\", 2087), (\"('children', 'of', 'the')\", 1795), (\"('house', 'of', 'the')\", 1583), (\"('of', 'son', 'the')\", 1527), (\"('and', 'lord', 'the')\", 1432), (\"('land', 'of', 'the')\", 1025), (\"('lord', 'saith', 'the')\", 866), (\"('of', 'out', 'the')\", 858), (\"('king', 'of', 'the')\", 827), (\"('and', 'i', 'will')\", 823)]\n"
     ]
    }
   ],
   "source": [
    "!python SortedTriGram_runner.py data/bible+shakes.nopunc.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you this is second line\n"
     ]
    }
   ],
   "source": [
    "s= \"hello how are you\"\n",
    "s2= \"this is second line\"\n",
    "v= s.split()[-2:]\n",
    "vs=\" \".join(v)\n",
    "print vs+\" \"+s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##Homework 4.4\n",
    "Create graphs to explain the relationship of the frequency of monograms ( words ) to bigrams and trigam frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordFrequency.py\n"
     ]
    }
   ],
   "source": [
    "%%file WordFrequency.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "lastWord=None\n",
    "lastWordTrigram=None\n",
    "\n",
    "class WordFrequency(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        # yield each word in the line\n",
    "        # for word in WORD_RE.findall(line):\n",
    "        if len(line.strip()) != 0 :\n",
    "            global lastWord\n",
    "            global lastWordTrigram\n",
    "            if lastWord is None and lastWordTrigram is None:\n",
    "                lastWord = \"\"\n",
    "                lastWordTrigram = \"\"\n",
    "            from_prev_line_trigram=\" \".join(lastWordTrigram)    \n",
    "            updatedline_trigram=from_prev_line_trigram+\" \"+line\n",
    "            updatedline_bigram=lastWord+\" \"+line\n",
    "            newword_trigram=nltk.word_tokenize(updatedline_trigram)\n",
    "            newword_bigram=nltk.word_tokenize(updatedline_bigram)\n",
    "            yield \"monograms\",len(list(nltk.ngrams(nltk.word_tokenize(line),1)))\n",
    "            #for bigram in nltk.bigrams(newword):\n",
    "            yield \"bigram\", len(list(nltk.bigrams(newword_bigram)))\n",
    "            #for word in nltk.ngrams(newword,3)\n",
    "            yield \"trigram\", len(list(nltk.ngrams(newword_trigram,3)))\n",
    "            lastWord = updatedline_bigram.split()[-1]\n",
    "            lastWordTrigram=updatedline_trigram.split()[-2:]\n",
    "        \n",
    "    def combiner(self, key, values):\n",
    "        yield None,(key, sum(values))\n",
    "        \n",
    "    def reducer(self,_,values):\n",
    "        s=100\n",
    "        print \"it is \",s\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    lastWordTrigram=None\n",
    "    WordFrequency.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no configs found; falling back on auto-configuration\n",
      "no configs found; falling back on auto-configuration\n",
      "creating tmp directory /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710\n",
      "\n",
      "PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "\n",
      "writing to /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710/step-0-mapper_part-00000\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "writing to /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710/step-0-mapper-sorted\n",
      "> sort /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710/step-0-mapper_part-00000\n",
      "writing to /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710/step-0-reducer_part-00000\n",
      "<generator object <genexpr> at 0x106e24460>\n",
      "Counters from step 1:\n",
      "  (no counters found)\n",
      "Moving /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710/step-0-reducer_part-00000 -> /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710/output/part-00000\n",
      "Streaming final output from /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710/output\n",
      "removing tmp directory /var/folders/fx/smy55tc51136lly1r1k3ypzr0000gn/T/WordFrequency.harish.20151027.192523.893710\n"
     ]
    }
   ],
   "source": [
    "!python WordFrequency.py bible+shakes.nopunc.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nodTJrCHHRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10927f410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "f = open('bible+shakes.nopunc.txt')\n",
    "raw = f.read()\n",
    "\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "\n",
    "#Create your bigrams\n",
    "monograms = len(list(nltk.ngrams(tokens,1))) #1752212\n",
    "bigrams = len(list(nltk.ngrams(tokens,2)))\n",
    "trigrams = len(list(nltk.ngrams(tokens,3)))\n",
    "'''\n",
    "fre=[monograms,bigrams,trigrams]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=15)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Frequency', fontsize=15)\n",
    "ax.set_ylabel('count' , fontsize=15)\n",
    "ax.set_title('Top 5 languages', fontsize=15, fontweight='bold')\n",
    "fre.plot(ax=ax, kind='bar', color='red')\n",
    "'''\n",
    "\n",
    "N = 3\n",
    "WordFrequency = (monograms,bigrams,trigrams)\n",
    "\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, WordFrequency, width, color='g')\n",
    "\n",
    "\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( ('Monogram', 'Bigram', 'Trigram') )\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python bargraph.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
