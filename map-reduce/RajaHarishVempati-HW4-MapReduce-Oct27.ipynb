{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mrjobs as mr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 4\n",
    "\n",
    "Copy this notebook. Rename it as: YOURNAME-HW4-mapreduce-XX\n",
    "\n",
    "with your name replacing YOURNAME and the xx replaced with the date you submit or copy this HW.\n",
    "\n",
    ".\n",
    "\n",
    "Upload your completed jupyter notebook to elearning site as your homework submission. Do not put this notebook on your github.\n",
    "\n",
    "\n",
    "Do all the homeworks problems below:\n",
    "As noted doing the homework gets a 3 out of 5. To do more create tutorials on how to use Map reduce for different analysis that were not assigned in this HW.\n",
    "\n",
    "Use the data+shakes.nonpunc.txt file as the source of you analysis in this homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Homework 4.1\n",
    " A bigram is the combination of words.  Find the 10 most common bigrams from the text.  Order counts in the bigram combination for example \"in the\" is not the same bigram as \"the in\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 7.0.3, however version 7.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /Users/harish/Documents/anaconda/anaconda/lib/python2.7/site-packages\n"
     ]
    }
   ],
   "source": [
    "import pip    \n",
    "def install(package):\n",
    "   pip.main(['install', package])\n",
    "\n",
    "install('mrjob')\n",
    "install('nltk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the Assignment is as follows:\n",
    "\n",
    "1) Each Question has MapReduce python file(which calculates bigrams/trigrams) and an additional python file(runner.py) to run corresponding MapReduce file and additional processing such as displaying top 10 results.\n",
    "\n",
    "2) The Runner program take inputfile as commandline argument and execute the map reduce job on that particular file.Here for all questions the textfile used was 'bible+shakes.nopunc.txt'\n",
    "\n",
    "3) As the inputfile has multiple lines, while processing bigrams the last word from previous line is appended to next line, in order to acheive the results similar to processing file which has single line.A similar logic for trigrams, where the last two words from previous line was appended to next line.\n",
    "\n",
    "4) All the runner.py files are same,they differ only by map reduce job they execute.I tried to use only one runner.py  by providing mapreduce job as command line argument along with the inputfile.But unfortunately I couldn't finish that.\n",
    "\n",
    "5) Assuming that input file is clean, no additional processing is done.\n",
    "\n",
    "6) For 4.4 to draw the graph, calculated mono,bi and trigrams for a portion of input file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRBiGramCount.py\n"
     ]
    }
   ],
   "source": [
    "%%file MRBiGramCount.py   \n",
    "\n",
    "#The MapReduce Job for calucalting bigrams.\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "lastWord=None\n",
    "\n",
    "class MRBiGramCount(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        if len(line.strip()) != 0 :\n",
    "            global lastWord\n",
    "            if lastWord is None:\n",
    "                lastWord = \"\"\n",
    "            updatedline=lastWord+\" \"+line\n",
    "            newword=nltk.word_tokenize(updatedline)\n",
    "            for word in nltk.bigrams(newword):\n",
    "                yield (word, 1)\n",
    "            lastWord = updatedline.split()[-1]\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        SORT_VALUES = True\n",
    "        yield (word),sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    counter=0\n",
    "    MRBiGramCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from MRBiGramCount import MRBiGramCount\r\n",
      "import sys\r\n",
      "import json\r\n",
      "import operator\r\n",
      "from collections import OrderedDict\r\n",
      "from collections import Counter\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    # Creates an instance of our MRJob subclass\r\n",
      "    job = MRBiGramCount(args=sys.argv[1:])\r\n",
      "    with job.make_runner() as runner:\r\n",
      "        # Run the job\r\n",
      "        runner.run()\r\n",
      "  \r\n",
      "        # Process the output\r\n",
      "        data=OrderedDict()\r\n",
      "        for line in runner.stream_output():\r\n",
      "            key, value = job.parse_output_line(line)\r\n",
      "            data[str(tuple(key))]=value\r\n",
      "         \r\n",
      "        sorted_x= OrderedDict()\r\n",
      "        ListItems=list(sorted_x)\r\n",
      "        print Counter(data).most_common(10)"
     ]
    }
   ],
   "source": [
    "!cat BiGramRunner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.runner\"\n",
      "[(\"('of', 'the')\", 13082), (\"('the', 'lord')\", 7148), (\"('and', 'the')\", 7071), (\"('in', 'the')\", 6782), (\"('to', 'the')\", 3822), (\"('i', 'will')\", 3518), (\"('and', 'he')\", 3040), (\"('shall', 'be')\", 3016), (\"('all', 'the')\", 2733), (\"('i', 'have')\", 2716)]\n"
     ]
    }
   ],
   "source": [
    "!python BiGramRunner.py data/bible+shakes.nopunc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Homework 4.2\n",
    "Now do the same analysis but make the word order not count \"in the\" == \"the in\".  Find the 10 most common ordered bigrams from the alice text.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SortedBiGramCount.py\n"
     ]
    }
   ],
   "source": [
    "%%file SortedBiGramCount.py  \n",
    "\n",
    "#The MapReduce Job for calucalting ordered bigrams.\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "lastWord=None\n",
    "counter=0\n",
    "class SortedBiGramCount(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        global lastWord\n",
    "        global counter\n",
    "        if lastWord is None:\n",
    "            lastWord = \"\"\n",
    "        updatedline=lastWord+\" \"+line\n",
    "        newword=nltk.word_tokenize(updatedline)\n",
    "        for word in nltk.bigrams(newword):\n",
    "            sortedbigram= sorted(word)\n",
    "            yield (sortedbigram, 1)\n",
    "        if(len(line.split()) <= 0):\n",
    "            counter=counter+1\n",
    "        else:\n",
    "             lastWord = updatedline.split()[-1]\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        SORT_VALUES = True\n",
    "        yield (word),sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    counter=0\n",
    "    SortedBiGramCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from SortedBiGramCount import SortedBiGramCount\r\n",
      "import sys\r\n",
      "import json\r\n",
      "import operator\r\n",
      "from collections import OrderedDict\r\n",
      "from collections import Counter\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    # Creates an instance of our MRJob subclass\r\n",
      "    job=SortedBiGramCount(args=sys.argv[1:])\r\n",
      "    with job.make_runner() as runner:\r\n",
      "        # Run the job\r\n",
      "        runner.run()\r\n",
      "   \r\n",
      "        # Process the output\r\n",
      "        data=OrderedDict()\r\n",
      "        for line in runner.stream_output():\r\n",
      "            key, value = job.parse_output_line(line)\r\n",
      "            data[str(tuple(key))]=value \r\n",
      "\r\n",
      "        sorted_x= OrderedDict()\r\n",
      "        ListItems=list(sorted_x)\r\n",
      "        print Counter(data).most_common(10)"
     ]
    }
   ],
   "source": [
    "!cat sortedbigram_runner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.runner\"\n",
      "[(\"('of', 'the')\", 13082), (\"('lord', 'the')\", 7419), (\"('and', 'the')\", 7071), (\"('in', 'the')\", 6783), (\"('i', 'will')\", 4156), (\"('the', 'to')\", 3822), (\"('have', 'i')\", 3182), (\"('and', 'he')\", 3160), (\"('be', 'shall')\", 3018), (\"('am', 'i')\", 2912)]\n"
     ]
    }
   ],
   "source": [
    "!python sortedbigram_runner.py data/bible+shakes.nopunc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Homework 4.3\n",
    "A trigram are three word combintation.  Find the 10 most common ordered trigrams from the alice text.  Make it so that the order of the words do not count in the trigram combination for example \"in the air\" is the same trigram as \"the air in\" or \"air in the\"...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting SortedTriGramCount.py\n"
     ]
    }
   ],
   "source": [
    "%%file SortedTriGramCount.py  \n",
    "\n",
    "#The MapReduce Job for calucalting ordered trigrams.\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "lastWord=None\n",
    "\n",
    "class SortedTriGramCount(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        global lastWord\n",
    "        global counter\n",
    "        if len(line.strip()) != 0 :\n",
    "            if lastWord is None:\n",
    "                lastWord = \"\"\n",
    "            from_prev_line=\" \".join(lastWord)    \n",
    "            updatedline=from_prev_line+\" \"+line\n",
    "            newword=nltk.word_tokenize(updatedline)\n",
    "            for word in nltk.ngrams(newword,3):\n",
    "                sortedbigram= sorted(word)\n",
    "                yield (sortedbigram, 1)\n",
    "                lastWord = updatedline.split()[-2:]\n",
    "        \n",
    "\n",
    "   \n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        SORT_VALUES = True\n",
    "        yield (word),sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    SortedTriGramCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from SortedTriGramCount import SortedTriGramCount\r\n",
      "import sys\r\n",
      "import json\r\n",
      "import operator\r\n",
      "from collections import OrderedDict\r\n",
      "from collections import Counter\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    # Creates an instance of our MRJob subclass\r\n",
      "    job=SortedTriGramCount(args=sys.argv[1:])\r\n",
      "    with job.make_runner() as runner:\r\n",
      "        # Run the job\r\n",
      "        runner.run()\r\n",
      "\r\n",
      "        \r\n",
      "        \r\n",
      "\r\n",
      "        #print json.dumps(data)    \r\n",
      "        # Process the output\r\n",
      "        data=OrderedDict()\r\n",
      "        for line in runner.stream_output():\r\n",
      "            key, value = job.parse_output_line(line)\r\n",
      "            #print 'key:', key, 'value:', value\r\n",
      "            data[str(tuple(key))]=value\r\n",
      "        # print(json.dumps(data)) \r\n",
      "\r\n",
      "        #sorted_x = sorted(data.items(), key=data.get)\r\n",
      "        sorted_x= OrderedDict()\r\n",
      "        #sorted_x = sorted(data.items(), key=operator.itemgetter(1))\r\n",
      "        #sorted_x=sorted(data.values())\r\n",
      "        ListItems=list(sorted_x)\r\n",
      "        #for words in ListItems[-5:]:\r\n",
      "        #\tprint words\r\n",
      "        print Counter(data).most_common(10)"
     ]
    }
   ],
   "source": [
    "!cat SortedTriGram_runner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.runner\"\r\n"
     ]
    }
   ],
   "source": [
    "!python SortedTriGram_runner.py data/bible+shakes.nopunc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##Homework 4.4\n",
    "Create graphs to explain the relationship of the frequency of monograms ( words ) to bigrams and trigam frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordFrequency.py\n"
     ]
    }
   ],
   "source": [
    "%%file WordFrequency.py  #The MapReduce Job for calucalting frequency of monograms,bigrams and trigrams.\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "\n",
    "lastWord=None\n",
    "lastWordTrigram=None\n",
    "\n",
    "class WordFrequency(MRJob):\n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        if len(line.strip()) != 0 :\n",
    "            global lastWord\n",
    "            global lastWordTrigram\n",
    "            if lastWord is None and lastWordTrigram is None:\n",
    "                lastWord = \"\"\n",
    "                lastWordTrigram = \"\"\n",
    "            from_prev_line_trigram=\" \".join(lastWordTrigram)    \n",
    "            updatedline_trigram=from_prev_line_trigram+\" \"+line\n",
    "            updatedline_bigram=lastWord+\" \"+line\n",
    "            newword_trigram=nltk.word_tokenize(updatedline_trigram)\n",
    "            newword_bigram=nltk.word_tokenize(updatedline_bigram)\n",
    "            yield \"monograms\",len(list(nltk.ngrams(nltk.word_tokenize(line),1)))\n",
    "            yield \"bigram\", len(list(nltk.bigrams(newword_bigram)))\n",
    "            yield \"trigram\", len(list(nltk.ngrams(newword_trigram,3)))\n",
    "            lastWord = updatedline_bigram.split()[-1]\n",
    "            lastWordTrigram=updatedline_trigram.split()[-2:]\n",
    "        \n",
    "    def combiner(self, key, values):\n",
    "        yield key,sum(values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lastWord=None\n",
    "    lastWordTrigram=None\n",
    "    WordFrequency.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from WordFrequency import WordFrequency\r\n",
      "import sys\r\n",
      "import json\r\n",
      "import operator\r\n",
      "from collections import OrderedDict\r\n",
      "from collections import Counter\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    # Creates an instance of our MRJob subclass\r\n",
      "    job=WordFrequency(args=sys.argv[1:])\r\n",
      "    with job.make_runner() as runner:\r\n",
      "        # Run the job\r\n",
      "        runner.run()\r\n",
      "\r\n",
      "        \r\n",
      "        \r\n",
      "\r\n",
      "        #print json.dumps(data)    \r\n",
      "        # Process the output\r\n",
      "        f = open(\"result.txt\", \"w\")\r\n",
      "        data=OrderedDict()\r\n",
      "        for line in runner.stream_output():\r\n",
      "            key, value = job.parse_output_line(line)\r\n",
      "            print 'key:', key, 'value:', value\r\n",
      "            f.write(str(str(key)+\" \"+str(value)))\r\n",
      "            f.write(\"\\n\")\r\n",
      "        f.close()"
     ]
    }
   ],
   "source": [
    "!cat WordFrequencyRunner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.runner\"\n",
      "key: bigram value: 216\n",
      "key: monograms value: 217\n",
      "key: trigram value: 215\n"
     ]
    }
   ],
   "source": [
    "!python WordFrequencyRunner.py bible+shakes.nopunc.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams  216\n",
      "Monograms  217\n",
      "Trigrams  215\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEKCAYAAAD0Luk/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10842cb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "#The count is done for the portion of input file.\n",
    "\n",
    "#The relationship between monograms, bigrams and trigrams is, every time bigram count is one less than monogram,\n",
    "#and trigram is two less than monogram.\n",
    "\n",
    "\n",
    "#The FrequencyCount runner file write the map reduce job results to a 'result.txt' and I am using data from this \n",
    "#result file to draw the graph.\n",
    "\n",
    "f = open('result.txt')\n",
    "for line in f.readlines():\n",
    "    if 'bigram' in line:\n",
    "        bigrams=int(line.split()[-1])\n",
    "        print 'Bigrams ',bigrams\n",
    "    elif 'trigram' in line:\n",
    "        trigrams=int(line.split()[-1])\n",
    "        print 'Trigrams ',trigrams\n",
    "    else:\n",
    "        monograms=int(line.split()[-1])\n",
    "        print 'Monograms ',monograms\n",
    "N = 3\n",
    "WordFrequency = (monograms,bigrams,trigrams)\n",
    "\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.35       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, WordFrequency, width, color='g')\n",
    "\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Word Count')\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( ('Monogram', 'Bigram', 'Trigram') )\n",
    "plt.show\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
